import streamlit as st
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.text_splitter import CharacterTextSplitter

# ğŸš€ Cáº¥u hÃ¬nh
st.title("ğŸ“š Chatbot tá»« tÃ i liá»‡u trong repo")
st.write("Nháº­p cÃ¢u há»i vÃ  chatbot sáº½ tráº£ lá»i dá»±a trÃªn ná»™i dung tÃ i liá»‡u.")

# ğŸ§© Äá»c dá»¯ liá»‡u
with open("docs/data.txt", "r", encoding="utf-8") as f:
    raw_text = f.read()

# âœ‚ï¸ TÃ¡ch Ä‘oáº¡n vÄƒn
text_splitter = CharacterTextSplitter(separator="\n", chunk_size=500, chunk_overlap=50)
texts = text_splitter.split_text(raw_text)

# ğŸ§  Táº¡o embedding vÃ  index
embeddings = OpenAIEmbeddings()  # cáº§n thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng OPENAI_API_KEY
docsearch = FAISS.from_texts(texts, embeddings)

# ğŸ” Táº¡o chain
llm = ChatOpenAI(temperature=0)
qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever())

# ğŸ’¬ Giao diá»‡n há»i Ä‘Ã¡p
question = st.text_input("CÃ¢u há»i:")

if question:
    answer = qa_chain.run(question)
    st.markdown("#### âœ… Tráº£ lá»i:")
    st.write(answer)
